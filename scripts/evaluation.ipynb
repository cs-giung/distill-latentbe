{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import jax_utils\n",
    "from flax.training import checkpoints\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from giung2.config import get_cfg\n",
    "from giung2.data.build import build_dataloaders\n",
    "from giung2.modeling.build import build_model\n",
    "from giung2.evaluation import get_optimal_temperature, temperature_scaling, evaluate_acc, evaluate_nll, evaluate_ece\n",
    "\n",
    "CPU = jax.devices(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x4.yaml\", allow_unsafe=True)\n",
    "cfg.DATASETS.ROOT = \"../datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model & dataloaders\n",
    "model = build_model(cfg)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "def initialize_model(key, model, im_shape, im_dtype):\n",
    "    @jax.jit\n",
    "    def init(*args):\n",
    "        return model.init(*args)\n",
    "    var_dict = init({'params': key}, jnp.ones(im_shape, im_dtype))\n",
    "    return var_dict\n",
    "\n",
    "if cfg.DATASETS.NAME in ['CIFAR10',]:\n",
    "    image_shape = (1, 32, 32, 3,)\n",
    "    num_classes = 10\n",
    "elif cfg.DATASETS.NAME in ['CIFAR100',]:\n",
    "    image_shape = (1, 32, 32, 3,)\n",
    "    num_classes = 100\n",
    "\n",
    "im_dtype = jnp.float32\n",
    "initialize_model(rng, model, image_shape, im_dtype)\n",
    "\n",
    "dataloaders = build_dataloaders(cfg, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher (DE-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC    | NLL    | ECE    | cNLL   | cECE   |\n",
      "| 81.08  | 0.715  | 0.030  | 0.709  | 0.018  |\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained weights\n",
    "teacher_var_dict_list = []\n",
    "for idx in range(4):\n",
    "    ckpt = checkpoints.restore_checkpoint(\n",
    "        f\"../outputs/C100_WRN28x4/SGD/{idx}/best_acc1\", target=None)\n",
    "    teacher_var_dict_list.append({\n",
    "        'params': ckpt['params'],\n",
    "        'image_stats': ckpt['image_stats'],\n",
    "        'batch_stats': ckpt['batch_stats'],})\n",
    "    del ckpt\n",
    "\n",
    "# make predictions\n",
    "def predict(var_dict_list, images):\n",
    "    return jnp.stack([\n",
    "        model.apply(\n",
    "            var_dict, images, mutable='intermediates'\n",
    "        )[1]['intermediates']['classifier']['logits'][0]\n",
    "        for var_dict in var_dict_list\n",
    "    ], axis=1) # [N, M, K]\n",
    "\n",
    "predict = jax.pmap(partial(predict, teacher_var_dict_list), axis_name='batch')\n",
    "\n",
    "def make_predictions(dataloader, desc):\n",
    "    true_labels, pred_logits = [], []\n",
    "    for batch in tqdm(dataloader, desc=desc, leave=False):\n",
    "        labels = jax.device_put(jnp.concatenate(        batch['labels'] ), CPU)\n",
    "        logits = jax.device_put(jnp.concatenate(predict(batch['images'])), CPU)\n",
    "        true_labels.append(labels)\n",
    "        pred_logits.append(logits)\n",
    "    return jnp.concatenate(true_labels), jnp.concatenate(pred_logits)\n",
    "\n",
    "val_true_labels, val_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['val_loader'](rng=None), size=2),\n",
    "    'Make predictions on valid examples')\n",
    "tst_true_labels, tst_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['tst_loader'](rng=None), size=2),\n",
    "    'Make predictions on test examples')\n",
    "\n",
    "# evaluate predictions\n",
    "val_confidences = jnp.mean(jax.nn.softmax(val_pred_logits, axis=-1), axis=1) # [N, K,]\n",
    "tst_confidences = jnp.mean(jax.nn.softmax(tst_pred_logits, axis=-1), axis=1) # [N, K,]\n",
    "t_opt = get_optimal_temperature(val_confidences, val_true_labels, log_input=False)\n",
    "print('| ACC    | NLL    | ECE    | cNLL   | cECE   |')\n",
    "print('| {:.2f}  | {:.3f}  | {:.3f}  | {:.3f}  | {:.3f}  |'.format(\n",
    "    evaluate_acc(                    tst_confidences,                          tst_true_labels, log_input=False) * 100,\n",
    "    evaluate_nll(                    tst_confidences,                          tst_true_labels, log_input=False),\n",
    "    evaluate_ece(                    tst_confidences,                          tst_true_labels, log_input=False)['ece'],\n",
    "    evaluate_nll(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False),\n",
    "    evaluate_ece(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False)['ece'],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student (KD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXPERIMENTS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC    | NLL    | ECE    | cNLL   | cECE   |\n",
      "| 79.00  | 1.064  | 0.136  | 0.865  | 0.041  |\n",
      "| 79.53  | 1.064  | 0.129  | 0.867  | 0.044  |\n",
      "| 79.11  | 1.081  | 0.135  | 0.873  | 0.045  |\n",
      "| 79.03  | 1.080  | 0.135  | 0.877  | 0.044  |\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained weights\n",
    "student_var_dict_list = []\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    ckpt = checkpoints.restore_checkpoint(\n",
    "        f\"../outputs/C100_WRN28x4/KD_DE4/{idx}/best_acc1\", target=None)\n",
    "    student_var_dict_list.append({\n",
    "        'params': ckpt['params'],\n",
    "        'image_stats': ckpt['image_stats'],\n",
    "        'batch_stats': ckpt['batch_stats'],})\n",
    "    del ckpt\n",
    "\n",
    "# make predictions\n",
    "def predict(var_dict_list, images):\n",
    "    return jnp.stack([\n",
    "        model.apply(\n",
    "            var_dict, images, mutable='intermediates'\n",
    "        )[1]['intermediates']['classifier']['logits'][0]\n",
    "        for var_dict in var_dict_list\n",
    "    ], axis=1) # [N, M, K]\n",
    "\n",
    "predict = jax.pmap(partial(predict, student_var_dict_list), axis_name='batch')\n",
    "\n",
    "def make_predictions(dataloader, desc):\n",
    "    true_labels, pred_logits = [], []\n",
    "    for batch in tqdm(dataloader, desc=desc, leave=False):\n",
    "        labels = jax.device_put(jnp.concatenate(        batch['labels'] ), CPU)\n",
    "        logits = jax.device_put(jnp.concatenate(predict(batch['images'])), CPU)\n",
    "        true_labels.append(labels)\n",
    "        pred_logits.append(logits)\n",
    "    return jnp.concatenate(true_labels), jnp.concatenate(pred_logits)\n",
    "\n",
    "val_true_labels, val_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['val_loader'](rng=None), size=2),\n",
    "    'Make predictions on valid examples')\n",
    "tst_true_labels, tst_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['tst_loader'](rng=None), size=2),\n",
    "    'Make predictions on test examples')\n",
    "\n",
    "# evaluate predictions\n",
    "print('| ACC    | NLL    | ECE    | cNLL   | cECE   |')\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    val_confidences = jax.nn.softmax(val_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    tst_confidences = jax.nn.softmax(tst_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    t_opt = get_optimal_temperature(val_confidences, val_true_labels, log_input=False)\n",
    "    print('| {:.2f}  | {:.3f}  | {:.3f}  | {:.3f}  | {:.3f}  |'.format(\n",
    "        evaluate_acc(                    tst_confidences,                          tst_true_labels, log_input=False) * 100,\n",
    "        evaluate_nll(                    tst_confidences,                          tst_true_labels, log_input=False),\n",
    "        evaluate_ece(                    tst_confidences,                          tst_true_labels, log_input=False)['ece'],\n",
    "        evaluate_nll(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False),\n",
    "        evaluate_ece(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False)['ece'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student (KD + LatentBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC    | NLL    | ECE    | cNLL   | cECE   |\n",
      "| 79.03  | 1.024  | 0.130  | 0.850  | 0.045  |\n",
      "| 79.48  | 0.999  | 0.125  | 0.838  | 0.045  |\n",
      "| 79.41  | 1.014  | 0.128  | 0.842  | 0.046  |\n",
      "| 79.37  | 1.010  | 0.126  | 0.843  | 0.046  |\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained weights\n",
    "student_var_dict_list = []\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    ckpt = checkpoints.restore_checkpoint(\n",
    "        f\"../outputs/C100_WRN28x4/KD_DE4_LatentBE/{idx}/best_acc1\", target=None)\n",
    "    \n",
    "    # merge rank-one factors\n",
    "    ckpt['params']['classifier']['Linear_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['classifier']['Linear_BatchEnsemble_0']['r'], axis=0), axis=1)\n",
    "    ckpt['params']['classifier']['Linear_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['classifier']['Linear_BatchEnsemble_0']['s'], axis=0), axis=0)\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']['r']\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']['s']\n",
    "    ckpt['params']['classifier']['Linear_0'] = ckpt['params']['classifier']['Linear_BatchEnsemble_0']\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']\n",
    "    \n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['r']\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['s']\n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_0'] = ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']\n",
    "    \n",
    "    for block_name in [f'BasicBlock_{jdx}' for jdx in range(12)]:\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['s']\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_0'] = ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']\n",
    "        \n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['s']\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_1'] = ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']\n",
    "    \n",
    "    for block_name in [f'BasicBlock_{jdx}' for jdx in [0, 4, 8,]]:\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['s']\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_0'] = ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']\n",
    "    \n",
    "    student_var_dict_list.append({\n",
    "        'params': ckpt['params'],\n",
    "        'image_stats': ckpt['image_stats'],\n",
    "        'batch_stats': ckpt['batch_stats'],})\n",
    "    \n",
    "    del ckpt\n",
    "\n",
    "# make predictions\n",
    "def predict(var_dict_list, images):\n",
    "    return jnp.stack([\n",
    "        model.apply(\n",
    "            var_dict, images, mutable='intermediates'\n",
    "        )[1]['intermediates']['classifier']['logits'][0]\n",
    "        for var_dict in var_dict_list\n",
    "    ], axis=1) # [N, M, K]\n",
    "\n",
    "predict = jax.pmap(partial(predict, student_var_dict_list), axis_name='batch')\n",
    "\n",
    "def make_predictions(dataloader, desc):\n",
    "    true_labels, pred_logits = [], []\n",
    "    for batch in tqdm(dataloader, desc=desc, leave=False):\n",
    "        labels = jax.device_put(jnp.concatenate(        batch['labels'] ), CPU)\n",
    "        logits = jax.device_put(jnp.concatenate(predict(batch['images'])), CPU)\n",
    "        true_labels.append(labels)\n",
    "        pred_logits.append(logits)\n",
    "    return jnp.concatenate(true_labels), jnp.concatenate(pred_logits)\n",
    "\n",
    "val_true_labels, val_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['val_loader'](rng=None), size=2),\n",
    "    'Make predictions on valid examples')\n",
    "tst_true_labels, tst_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['tst_loader'](rng=None), size=2),\n",
    "    'Make predictions on test examples')\n",
    "\n",
    "# evaluate predictions\n",
    "print('| ACC    | NLL    | ECE    | cNLL   | cECE   |')\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    val_confidences = jax.nn.softmax(val_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    tst_confidences = jax.nn.softmax(tst_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    t_opt = get_optimal_temperature(val_confidences, val_true_labels, log_input=False)\n",
    "    print('| {:.2f}  | {:.3f}  | {:.3f}  | {:.3f}  | {:.3f}  |'.format(\n",
    "        evaluate_acc(                    tst_confidences,                          tst_true_labels, log_input=False) * 100,\n",
    "        evaluate_nll(                    tst_confidences,                          tst_true_labels, log_input=False),\n",
    "        evaluate_ece(                    tst_confidences,                          tst_true_labels, log_input=False)['ece'],\n",
    "        evaluate_nll(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False),\n",
    "        evaluate_ece(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False)['ece'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student (KD + LatentBE + TDiv-SDiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ACC    | NLL    | ECE    | cNLL   | cECE   |\n",
      "| 79.98  | 0.808  | 0.071  | 0.777  | 0.044  |\n",
      "| 80.21  | 0.799  | 0.070  | 0.771  | 0.044  |\n",
      "| 79.99  | 0.792  | 0.074  | 0.764  | 0.037  |\n",
      "| 80.16  | 0.793  | 0.067  | 0.768  | 0.038  |\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained weights\n",
    "student_var_dict_list = []\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    ckpt = checkpoints.restore_checkpoint(\n",
    "        f\"../outputs/C100_WRN28x4/KD_DE4_LatentBE_TDivSDiv/{idx}/best_acc1\", target=None)\n",
    "    \n",
    "    # merge rank-one factors\n",
    "    ckpt['params']['classifier']['Linear_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['classifier']['Linear_BatchEnsemble_0']['r'], axis=0), axis=1)\n",
    "    ckpt['params']['classifier']['Linear_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['classifier']['Linear_BatchEnsemble_0']['s'], axis=0), axis=0)\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']['r']\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']['s']\n",
    "    ckpt['params']['classifier']['Linear_0'] = ckpt['params']['classifier']['Linear_BatchEnsemble_0']\n",
    "    del ckpt['params']['classifier']['Linear_BatchEnsemble_0']\n",
    "    \n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "        jnp.mean(ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['r']\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']['s']\n",
    "    ckpt['params']['backbone']['FirstBlock_0']['Conv2d_0'] = ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']\n",
    "    del ckpt['params']['backbone']['FirstBlock_0']['Conv2d_BatchEnsemble_0']\n",
    "    \n",
    "    for block_name in [f'BasicBlock_{jdx}' for jdx in range(12)]:\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']['s']\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_0'] = ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_0']\n",
    "        \n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']['s']\n",
    "        ckpt['params']['backbone'][block_name]['Conv2d_1'] = ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']\n",
    "        del ckpt['params']['backbone'][block_name]['Conv2d_BatchEnsemble_1']\n",
    "    \n",
    "    for block_name in [f'BasicBlock_{jdx}' for jdx in [0, 4, 8,]]:\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['r'], axis=0), axis=(0, 1, 3,))\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['w'] *= jnp.expand_dims(\n",
    "            jnp.mean(ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['s'], axis=0), axis=(0, 1, 2,))\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['r']\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']['s']\n",
    "        ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_0'] = ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']\n",
    "        del ckpt['params']['backbone'][block_name]['ProjectionShortcut_0']['Conv2d_BatchEnsemble_0']\n",
    "    \n",
    "    student_var_dict_list.append({\n",
    "        'params': ckpt['params'],\n",
    "        'image_stats': ckpt['image_stats'],\n",
    "        'batch_stats': ckpt['batch_stats'],})\n",
    "    \n",
    "    del ckpt\n",
    "\n",
    "# make predictions\n",
    "def predict(var_dict_list, images):\n",
    "    return jnp.stack([\n",
    "        model.apply(\n",
    "            var_dict, images, mutable='intermediates'\n",
    "        )[1]['intermediates']['classifier']['logits'][0]\n",
    "        for var_dict in var_dict_list\n",
    "    ], axis=1) # [N, M, K]\n",
    "\n",
    "predict = jax.pmap(partial(predict, student_var_dict_list), axis_name='batch')\n",
    "\n",
    "def make_predictions(dataloader, desc):\n",
    "    true_labels, pred_logits = [], []\n",
    "    for batch in tqdm(dataloader, desc=desc, leave=False):\n",
    "        labels = jax.device_put(jnp.concatenate(        batch['labels'] ), CPU)\n",
    "        logits = jax.device_put(jnp.concatenate(predict(batch['images'])), CPU)\n",
    "        true_labels.append(labels)\n",
    "        pred_logits.append(logits)\n",
    "    return jnp.concatenate(true_labels), jnp.concatenate(pred_logits)\n",
    "\n",
    "val_true_labels, val_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['val_loader'](rng=None), size=2),\n",
    "    'Make predictions on valid examples')\n",
    "tst_true_labels, tst_pred_logits = make_predictions(\n",
    "    jax_utils.prefetch_to_device(dataloaders['tst_loader'](rng=None), size=2),\n",
    "    'Make predictions on test examples')\n",
    "\n",
    "# evaluate predictions\n",
    "print('| ACC    | NLL    | ECE    | cNLL   | cECE   |')\n",
    "for idx in range(NUM_EXPERIMENTS):\n",
    "    val_confidences = jax.nn.softmax(val_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    tst_confidences = jax.nn.softmax(tst_pred_logits, axis=-1)[:, idx, :] # [N, K,]\n",
    "    t_opt = get_optimal_temperature(val_confidences, val_true_labels, log_input=False)\n",
    "    print('| {:.2f}  | {:.3f}  | {:.3f}  | {:.3f}  | {:.3f}  |'.format(\n",
    "        evaluate_acc(                    tst_confidences,                          tst_true_labels, log_input=False) * 100,\n",
    "        evaluate_nll(                    tst_confidences,                          tst_true_labels, log_input=False),\n",
    "        evaluate_ece(                    tst_confidences,                          tst_true_labels, log_input=False)['ece'],\n",
    "        evaluate_nll(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False),\n",
    "        evaluate_ece(temperature_scaling(tst_confidences, t_opt, log_input=False), tst_true_labels, log_input=False)['ece'],\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2065fe8fb1b00e0be4922aac81a3bdc98dbc6b7a0d4ce84d60e19c8982df874a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('egyun')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
